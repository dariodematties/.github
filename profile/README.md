# [Waggle AI@Edge](https://github.com/orgs/waggle-sensor/repositories)

Waggle is a state-of-the-art open-source platform for developing and deploying novel artificial intelligence algorithms and new sensors into distributed sensor networks.  By providing  advanced edge computing capabilities, researchers and practitioners using Waggle can analyze high-resolution instrument data at unprecedented speeds, providing new insights and answering scientific questions not previously possible.

The Waggle Platform is a research project at [Argonne National Laboratory](https://www.anl.gov/) and its innovative architecture leverages emerging technology in low-power processors, sensors, and cloud computing to build powerful and reliable sensor nodes that can actively analyze and respond to data. Cloud computing provides elastic resources for storing and computing on data.

Waggle is designed from the ground up with security, privacy, extensability, and survivability as key design points. The Waggle reference platforms and software are launching points. All of the software is Open Source, and the software is modular, so researchers can add their own sensors, computing pipelines, and data analysis.

The name for the project comes from nature’s wireless sensors — honeybees. Bees search far and wide for pollen, and report their findings back to the hive using a sophisticated dance called a “waggle dance“. The dance encodes the distance and angle to the food source, and is often similar to a figure-8 — which is why we picked [wa8.gl](http://wa8.gl/) as our domain name. Waggle is free under the terms of an open-source license. 

# Waggle AI@Edge Basics

Waggle is a new kind of reusable cyber-infrastructure to enable AI at the edge, iteratively developed over 8 years. The illustration below shows a high-level view of the Waggle AI@Edge architecture and enumerates the various software services, tools, and infrastructure pieces. 
Three major components combine to provide the Waggle AI@Edge infrastructure. 
 
First, there are the Waggle nodes, which are extensible and allow addition of new sensors and instruments. Second, there are the datacenter infrastructure elements, which support various services for data aggregation, application compiling, containerization, and profiling, data dissemination, control, and management of the nodes. Third is the overarching software cyberinfrastructure that interfaces the datacenter to the nodes and other cloud/HPC and users. The Waggle project provides various reference designs for the hardware nodes, an architecture and implementation for Beehive, and the software cyberinfrastructure is made available on GitHub as a collection of modules. 

## Waggle Nodes 
Following a modular design, nodes enable rapid integration of new sensor technologies, from LIDAR to precision micro-synchrophasors for analysis of electrical distribution systems. While the earlier version of Waggle only supported ARM32 architectures, in this Waggle AI@Edge release, we added support for a new class of advanced edge-focused computing hardware (ARM64 and x86-64). There are two kinds of Waggle Nodes: Wild Waggle Nodes are weatherized for remote, outdoor deployment in remote and hard-to-reach locations. An important feature of our design is the addition of resilience software and hardware elements. The Waggle manager, [Wagman](https://github.com/waggle-sensor/wagman), is a custom circuit board for environment and health monitoring, and actively controlling power. Wagman can disconnect malfunctioning devices or reboot components with backup software stacks, providing robust operation in remote and harsh locales. Designed to be extremely reliable and resilient, the new release of WagMan performs all these tasks entirely through hardware components, requiring no firmware or code. The next most important device is the Node Controller. It is a single-board Linux computer providing encrypted TCP/IP messaging, data caching, node health monitoring, and cybersecurity tools including cryptokey management and signed software. While the above tasks are its main priority, through container-based isolation technologies, the node controller is also available to run user applications on the dedicated CPU-GPU resources. Additional processing and storage elements can now be added to this basic construct, and they are called Edge Processors. A collection of components that provide power, networking, and embedded interfacing capabilities complete the basic node. This node can now be extended with sensors through standard Ethernet (POE), USB and other embedded protocols. 

## Waggle Blades
Waggle Blades are standard, commercially available blade servers intended for use in a machine room or extended temperature range telecom-grade blades. The Waggle platform supports blades with standard x86-64 CPUS and NVIDIA GPUs for AI@Edge compute jobs. As a Waggle Node, they run the complete Waggle software stack, and therefore can run Edge jobs, report data, and be remotely configured.

## Datacenter Infrastructure
The Waggle datacenter infrastructure is composed of 3 main subsystems - beehive, beekeeper and edge code repository (ECR). Beekeeper is the resource that registers, authenticates, authorizes, configures, manages, and controls the waggle nodes. It is the node cluster administrator. Next, Beehive offers node-data center bidirectional communication, data aggregation, storage, and dissemination capabilities. And finally, the ECR is an application repository, similar to Android’s Play Store and iOS’ App Store. Users can submit their edge applications into ECR, which are then compiled, composed into containers, and profiled for intelligently scheduling them as jobs at the edge. 

## Software Cyber Infrastructure
The collection of code that runs on the nodes and data center which form the Software part of the Cyber Infrastructure are composed as easily combinable modules. Users can use the implementations provided by Sage, or replace, modify, and extend as they see fit. Our design goal was to both quickly enable implementation of an end-to-end Waggle system, and also provide the flexibility for complete customization. The Core Services (CS), a set of essential modular components and tools, provide data APIs, communication mechanisms, communication API (Pywaggle), authentication, and management services to the entire framework. This includes: Storage & Storage API, Authorization Service, User Management and Authentication, Sage Continuous Integration, Public Streaming Service, and Waggle Web Portal. The Waggle Edge Stack (WES) includes the operating system image and Waggle services running on the Waggle nodes, as well as the AI/ML run-time libraries and tools. The core components for managing cybersecurity, certificate management, and managing system resources, such as power, memory, and cores are features implemented here. The Edge Scheduler (SES) handles updates to the edge computing algorithms. Containerized user apps in ECR can be scheduled on nodes by users with their authentication token, including pushing configuration changes. Users can also submit local “jobs'' that can be scheduled and run on nodes immediately during the development cycle. As a two-component system (Beehive and Node), the ES makes all configuration and system update decisions, and queues up changes that can be pushed out to nodes when they contact beehive.

## Waggle Operation 
Waggle nodes deployed in the field are extended with sensors, actuators, and other instruments to form a scientific instrument. Through real-time modification of the sensor’s parameters and by dynamically modifying how they process the data through Edge Codes, the Waggle nodes are essentially software-defined instruments. Users integrated their sensors through Linux OS drivers and any other software needed to interface with them. The nodes use TCP/IP based SSL encrypted communication to establish data (RabbitMQ and rsync-over-ssh implementation provided), control, and management (ssh and RabbitMQ) connections to Beehive, Beekeeper, and ECR. The nodes are designed to initiate communication with only the data-center resources, with no communication network ports open for other network devices to communicate with them. This extremely locked-down design provides a high level of cybersecurity. The design also enforces a hub-and-spoke architecture to the Waggle communication. Nodes can exchange messages with each other through the beehive, where the beehive operates as a store and forward communication hub. 
The main focus of Waggle AI@Edge is user-accessible edge computing utilizing AI/ML applications. The system hence provides three capabilities:

- A mechanism by which users can develop the edge algorithms on a node 
- A mechanism through which the algorithms can be verified and profiled for efficiency and system resource requirements 
- A mechanism through which users can submit an application to be executed on the nodes based on a set of conditions (environmental, time of the day, periodic etc.). 

Waggle users follow the steps above to create and deploy the software that defines their instrument. This software is written as plugins using the PyWaggle library, and composed into container images, before deployment in the nodes. 

The sensor and inference data generated by the user code in the nodes is aggregated and made available by Beehive through two mechanisms - a streaming service with API for real-time data, and a bulk download mechanism for curated archival data (common among science communities). Users can use the data for analysis, or further pipe them into global analysis applications on cloud or HPC services of their choosing using the Waggle data API. Users can then use their authentication tokens to modify the applications using the edge scheduler. 

On the whole, Waggle is a collection of hardware components composed and defined by a collection of software tools and services that allow the users to dynamically modify and steer the cyber infrastructure.


