# [Waggle AI@Edge](https://github.com/orgs/waggle-sensor/repositories)

Waggle is a state-of-the-art open-source platform for developing and deploying novel artificial intelligence algorithms and new sensors into distributed sensor networks.  By providing  advanced edge computing capabilities, researchers and practitioners using Waggle can analyze high-resolution instrument data at unprecedented speeds, providing new insights and answering scientific questions not previously possible.

The Waggle Platform is a research project at [Argonne National Laboratory](https://www.anl.gov/) and its innovative architecture leverages emerging technology in low-power processors, sensors, and cloud computing to build powerful and reliable sensor nodes that can actively analyze and respond to data. Cloud computing provides elastic resources for storing and computing on data.

Waggle is designed from the ground up with security, privacy, extensibility, and survivability as key design points. The Waggle reference platforms and software are launching points for customized Sensing and Instrumentation deployments. All of the software is open source and modular, so researchers can add their own sensors, computing pipelines, and data analysis.

The name for the project comes from nature’s wireless sensors — honeybees. Bees search far and wide for pollen, and report their findings back to the hive using a sophisticated dance called a [“waggle dance“](https://en.wikipedia.org/wiki/Waggle_dance). The dance encodes the distance and angle to the food source, and is often similar to a figure-8 — which is why we picked [wa8.gl](http://wa8.gl/) as our domain name. Waggle is free under the terms of an open-source license. 

Built as a set of open-source tools, plugins, and infrastructure codes, the specialized waggle software services offer greater efficiency and flexibility than traditional monolithic/single vendor designs. They are also applicable to new sensing technologies, scientific instruments, and infrastructure elements as they emerge. That includes new computing devices, data storage, networking technologies, communication protocols, and computing paradigms (fog, 5G MEC etc.) This capability is in especially high demand as scientists around the world embrace phenomenal growth in three directions - sensors, computing devices, and AI/ML algorithms. Together, the progress in these three domains has made it possible to sense and assimilate the world around us at a pace that was never before possible using algorithms that are beginning to write themselves.

# Waggle AI@Edge Basics

Iteratively developed over 8 years, Waggle is a new kind of reusable cyber-infrastructure to enable AI at the edge. The illustration below shows a high-level view of the Waggle AI@Edge architecture and enumerates the various software services, tools, and infrastructure elements. Two major components combine to provide the Waggle AI@Edge infrastructure. 
 
First, there are the Waggle nodes, which are extensible and allow integration of new sensors and instruments. Second, there are the software cyberinfrastructure elements, which support various services for aggregation and dissemination of data, compiling, containerization, and profiling of applications,  and control and management of the nodes. The overarching software cyberinfrastructure also connects the nodes to other cloud/HPC resources and users. The Waggle project on GitHub provides various reference designs for the hardware nodes and the software cyberinfrastructure as a collection of modules.
 
## Waggle Nodes

Following a modular design, nodes enable rapid integration of new sensor technologies, from LiDAR to precision micro-synchrophasors for analysis of electrical distribution systems. While the earlier version of Waggle only supported ARM32 architectures, in the most recent Waggle AI@Edge release, we added support for ARM64 and x86-64 edge-focused computing hardware. There are two kinds of Waggle Nodes:

**Wild Waggle Nodes (WWN)** are weatherized for remote, outdoor deployment in remote and hard-to-reach locations. An important feature of our design is the addition of resilience software and hardware elements. The Waggle manager, Wagman, is a custom circuit board for environment and health monitoring, and actively controlling power. Wagman can disconnect malfunctioning devices or reboot components with backup software stacks, providing robust operation in remote and harsh locales. Designed to be extremely reliable and resilient, the new release of Wagman (V5) performs all these tasks entirely through hardware components, requiring no firmware or code. The next most important device is the Node Controller. It is a single-board Linux computer providing encrypted TCP/IP messaging, data caching, node health monitoring, and access to connected sensors and actuators. While the above tasks are its main priority, through container-based isolation technologies, the node controller is also available to run user applications on the dedicated CPU-GPU resources. Additional processing called Edge Processors and storage elements can now be added to this basic construct. A collection of components that provide power, networking, and embedded interfacing capabilities complete the basic node. This node can now be extended with sensors through standard Ethernet (POE), USB and other embedded protocols. 

**Waggle Blades** are standard commercially available blade servers intended for use in a climate controlled machine room, or extended temperature range telecom-grade blades for harsher environments. The Waggle platform supports blades with standard x86-64 CPUs and NVIDIA GPUs for AI@Edge compute jobs. As a Waggle Node, they run the complete Waggle software stack, and therefore can run edge jobs, report data, and be remotely configured.

## Software Cyber Infrastructure: 

The collection of code that runs on the nodes and server infrastructure are composed as easily combinable modules. Users can use the implementations provided by Waggle, or replace, modify, and extend as they see fit. Our design goal was to both quickly enable implementation of an end-to-end Waggle system, and also provide the flexibility for complete customization. The Core Services (CS), a set of essential modular components and tools, provide data APIs, communication mechanisms, communication API (PyWaggle), authentication, and management services to the entire framework. This includes: storage & storage API, authorization service, user management and authentication, public data streaming, and Waggle web portal. The Waggle Edge Stack (WES) includes Waggle services running on the Waggle nodes, as well as the AI/ML run-time libraries and tools. The core components for managing cybersecurity, certificate management, and managing system resources, such as power, memory, and cores are features implemented here. Separately, Waggle provides OS images that incorporate the above components for a few ARM64 and x86-64 computing systems. The Waggle server infrastructure is composed of 3 main subsystems - Beehive, Beekeeper and edge code repository (ECR). Beekeeper is the resource that registers, authenticates, authorizes, configures, manages, and controls the Waggle nodes. It is the node cluster administrator. Next, Beehive offers bidirectional communication to the nodes, and data aggregation, storage and dissemination capabilities. And finally, the ECR is an application repository, similar to Android’s Play Store and iOS’ App Store. Users can submit their edge applications into ECR, which are then compiled, composed into containers, and profiled for intelligently scheduling them as jobs at the edge. In addition to scheduling the jobs, the Edge Scheduler (ES) handles updates to the edge computing algorithms. Containerized user applications in ECR can be scheduled on nodes by users with their authentication token, including pushing configuration changes. Users can also submit local “jobs'' that can be scheduled and run on nodes immediately during the development cycle. The ES makes all configuration and system update decisions, and queues up changes that can be pushed out to nodes when they connect to the Beehive. 

# Waggle Operation

Waggle nodes deployed in the field are extended with sensors, actuators, and other instruments to form a scientific instrument. Through real-time modification of the sensor’s parameters and by dynamically modifying how they process the data through edge codes, the Waggle nodes are essentially software-defined instruments. Users integrated their sensors through Linux OS drivers and any other software needed to interface with them. The nodes use TCP/IP based SSL encrypted communication to establish data (RabbitMQ and rsync-over-ssh implementation provided), control, and management (ssh and RabbitMQ) connections to Beehive, Beekeeper, and ECR. The nodes are designed to initiate communication with only the predefined server resources, with no communication network ports open for other network devices to communicate with them. This extremely locked-down design provides a high level of cybersecurity. The design also enforces a hub-and-spoke architecture to the Waggle communication. Nodes can exchange messages with each other through the Beehive, which can operate as a store and forward communication hub. 
The main focus of Waggle AI@Edge is user-accessible edge computing utilizing AI/ML applications. The system hence provides three capabilities:

- A mechanism by which users can develop the edge algorithms on a node 
- A mechanism through which the algorithms can be verified and profiled for efficiency and system resource requirements 
- A mechanism through which users can submit an application to be executed on the nodes based on a set of conditions (environmental, time of the day, periodic etc.). 

Waggle users follow the steps above to create and deploy the software that defines their instrument. This software is written as plugins using the PyWaggle library, and composed into container images, before deployment in the nodes by ES. 

The sensor and inference data generated by the user code in the nodes is aggregated and made available by Beehive through two mechanisms - a streaming service with API for real-time data, and a bulk download mechanism for curated archival data (common among science communities). Users can use the data for analysis, or further pipe them into global analysis applications on cloud or HPC services of their choosing using the Waggle data API. Users can then use their authentication tokens to modify the applications using the edge scheduler. 

On the whole, Waggle is a collection of hardware components composed and defined by a collection of software tools and services that allow the users to dynamically modify and steer the cyber infrastructure. 
